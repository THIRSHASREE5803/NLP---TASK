{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7afd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "##scrape a text\n",
    "from urllib import request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e3ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.gutenberg.org/files/98/98-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d342b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f7f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read and decode it\n",
    "raw=response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8255e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens=word_tokenize(raw)\n",
    "##list of words separated by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34352fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'A', 'Tale', 'of', 'Two', 'Cities', ',', 'by', 'Charles', 'Dickens', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'A', 'Tale', 'of', 'Two', 'Cities', 'A', 'Story', 'of', 'the', 'French', 'Revolution', 'Author', ':', 'Charles', 'Dickens', 'Release', 'Date', ':', 'January', ',', '1994', '[', 'eBook', '#', '98', ']', '[', 'Most', 'recently', 'updated', ':', 'December', '20', ',', '2020', ']', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', 'Produced', 'by', ':', 'Judith', 'Boss', 'and', 'David', 'Widger', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'A', 'TALE', 'OF', 'TWO', 'CITIES', '*', '*', '*', 'A', 'TALE', 'OF', 'TWO', 'CITIES', 'A', 'STORY', 'OF', 'THE', 'FRENCH', 'REVOLUTION', 'By', 'Charles', 'Dickens', 'CONTENTS', 'Book', 'the', 'First', '--', 'Recalled', 'to', 'Life', 'CHAPTER', 'I', 'The', 'Period', 'CHAPTER', 'II']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17f26ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##to clean we write regular expression like\"\\ufee to get rid of tags \n",
    "##beautiful soup for scraping different languages\n",
    "##with loop befor print cam do sen or word token\n",
    "##how many adj used personal pronouns penstate pos(45)\n",
    "##can also tty with html re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a621222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beautifulsoup\n",
    "#preprocessiong-RE to clean any html tagg\n",
    "#POS Tagging\n",
    "#!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71dbe94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2##nd Experiment\n",
    "#Stemming:snowball,lanscat,porters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00591d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cacti'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "porter.stem('cacti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f5466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works well for certain stemmerPorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b4c3fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "porter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2413eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thirsha'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "porter.stem('Thirsha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf2dbfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "porter.stem('Singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fef0a058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "porter=PorterStemmer()\n",
    "porter.stem('Singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1fca1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Walk'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "porter=RegexpStemmer('ing')\n",
    "porter.stem('Walking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56189151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "porter=RegexpStemmer('ing')\n",
    "porter.stem('singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b04f0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "porter=RegexpStemmer('ing$')\n",
    "porter.stem('singing')\n",
    "#sing,ring can break this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1515418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mang'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#snowball stemmer\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "snow=SnowballStemmer('french')\n",
    "snow.stem('manges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98cbd9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##The following languages are supported: Arabic, Danish, Dutch, English, Finnish, French, German, Hungarian, Italian,\n",
    "##Norwegian, Portuguese, Romanian, Russian, Spanish and Swedish.\n",
    "##The algorithm for English is documented here: Porter, M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c2f65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##add for loop to stem the entire passage\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "text=\"Natural language processing (NLP) is an interdisciplinary subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\"\n",
    "stemmed=[porter.stem(token) for token in text.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f14d508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', '(nlp)', 'is', 'an', 'interdisciplinari', 'subfield', 'of', 'linguistics,', 'comput', 'science,', 'and', 'artifici', 'intellig', 'concern', 'with', 'the', 'interact', 'between', 'comput', 'and', 'human', 'language,', 'in', 'particular', 'how', 'to', 'program', 'comput', 'to', 'process', 'and', 'analyz', 'larg', 'amount', 'of', 'natur', 'languag', 'data.', 'the', 'goal', 'is', 'a', 'comput', 'capabl', 'of', 'understand', 'the', 'content']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4d32a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "##eliminates e in porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d3ff4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##add for loop to stem the entire passage\n",
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "porter=PorterStemmer()\n",
    "text=\"Natural language processing (NLP) is an interdisciplinary subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\"\n",
    "stemmed=[porter.stem(token) for token in text.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f832d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', '(nlp)', 'is', 'an', 'interdisciplinari', 'subfield', 'of', 'linguistics,', 'comput', 'science,', 'and', 'artifici', 'intellig', 'concern', 'with', 'the', 'interact', 'between', 'comput', 'and', 'human', 'language,', 'in', 'particular', 'how', 'to', 'program', 'comput', 'to', 'process', 'and', 'analyz', 'larg', 'amount', 'of', 'natur', 'languag', 'data.', 'the', 'goal', 'is', 'a', 'comput', 'capabl', 'of', 'understand', 'the', 'content']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc982ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "madam\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "print(lemma.lemmatize(\"madam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51670002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "print(lemma.lemmatize(\"cacti\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd6c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "print(lemma.lemmatize(\"mice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f80e7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n"
     ]
    }
   ],
   "source": [
    "##lemmatizer allows to give am as be\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "print(lemma.lemmatize(\"am\",pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47d74363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n"
     ]
    }
   ],
   "source": [
    "##lemmatizer allows to give am as be\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "print(lemma.lemmatize(\"is\",pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3562bb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "##lemmatizer allows to give am as be\n",
    "#pos is parts of speech\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "print(lemma.lemmatize(\"good\",pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faffa9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
